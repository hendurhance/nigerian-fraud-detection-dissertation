{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# NIBSS Fraud Detection: Feature Importance Analysis\n",
        "\n",
        "This notebook provides comprehensive feature importance analysis for the optimized fraud detection models including:\n",
        "- Permutation importance analysis\n",
        "- SHAP (SHapley Additive exPlanations) values for interpretability\n",
        "- Channel-specific feature analysis\n",
        "- Temporal feature importance\n",
        "- Feature interaction analysis\n",
        "\n",
        "The analysis focuses on understanding which features contribute most to fraud detection performance and provides actionable insights for the Nigerian banking system."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-header",
      "metadata": {},
      "source": [
        "## Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# Load data and models\n",
        "data_splits = joblib.load('../data/processed/data_splits.pkl')\n",
        "best_models = joblib.load('../models/optimization_results.pkl')['best_models']\n",
        "data_info = joblib.load('../data/processed/data_info.pkl')\n",
        "\n",
        "X_test = data_splits['X_test']\n",
        "y_test = data_splits['y_test']\n",
        "X_val = data_splits['X_val']\n",
        "y_val = data_splits['y_val']\n",
        "\n",
        "print(\"Models and data loaded successfully!\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "permutation-header",
      "metadata": {},
      "source": [
        "## Permutation Feature Importance Analysis\n",
        "\n",
        "Permutation importance measures the decrease in model performance when a feature's values are randomly shuffled, providing a model-agnostic approach to feature importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feature-names-function",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to get feature names after preprocessing\n",
        "def get_feature_names(pipeline, original_features):\n",
        "    \"\"\"Extract feature names after preprocessing\"\"\"\n",
        "    preprocessor = pipeline.named_steps['preprocessor']\n",
        "\n",
        "    feature_names = []\n",
        "\n",
        "    # Numerical features\n",
        "    num_features = data_info['numerical_features']\n",
        "    feature_names.extend(num_features)\n",
        "\n",
        "    # Categorical features (one-hot encoded)\n",
        "    cat_low_features = data_info['categorical_low']\n",
        "    if hasattr(preprocessor.named_transformers_['cat_low'], 'get_feature_names_out'):\n",
        "        cat_names = preprocessor.named_transformers_['cat_low'].get_feature_names_out(cat_low_features)\n",
        "        feature_names.extend(cat_names)\n",
        "    else:\n",
        "        # Fallback for older sklearn versions\n",
        "        feature_names.extend([f\"{col}_encoded\" for col in cat_low_features])\n",
        "\n",
        "    # High cardinality categorical (target encoded)\n",
        "    cat_high_features = data_info['categorical_high']\n",
        "    feature_names.extend(cat_high_features)\n",
        "\n",
        "    # Time features\n",
        "    time_features = data_info['time_features']\n",
        "    feature_names.extend(time_features)\n",
        "\n",
        "    return feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "permutation-importance",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate permutation importance for each model\n",
        "perm_importance_results = {}\n",
        "\n",
        "for model_name, pipeline in best_models.items():\n",
        "    print(f\"\\nCalculating permutation importance for {model_name}...\")\n",
        "\n",
        "    # Get feature names\n",
        "    feature_names = get_feature_names(pipeline, data_info['numerical_features'] +\n",
        "                                      data_info['categorical_low'] +\n",
        "                                      data_info['categorical_high'] +\n",
        "                                      data_info['time_features'])\n",
        "\n",
        "    # Calculate permutation importance on validation set\n",
        "    perm_importance = permutation_importance(\n",
        "        pipeline, X_val, y_val,\n",
        "        n_repeats=10,\n",
        "        random_state=RANDOM_SEED,\n",
        "        scoring='roc_auc',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Store results\n",
        "    perm_importance_results[model_name] = {\n",
        "        'importances_mean': perm_importance.importances_mean,\n",
        "        'importances_std': perm_importance.importances_std,\n",
        "        'feature_names': feature_names\n",
        "    }\n",
        "\n",
        "    print(f\"Completed {model_name}\")\n",
        "\n",
        "print(\"\\nPermutation importance analysis completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "table49-header",
      "metadata": {},
      "source": [
        "## Table 4.9: Top 10 Features by Permutation Importance\n",
        "\n",
        "Summary table showing the most important features across all models with AUC decrease values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "table49",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process permutation importance results\n",
        "top_n = 10\n",
        "table_data = []\n",
        "\n",
        "for rank in range(1, top_n + 1):\n",
        "    row = {'Rank': rank}\n",
        "    \n",
        "    for model_name in ['logistic_regression', 'random_forest', 'xgboost']:\n",
        "        results = perm_importance_results[model_name]\n",
        "        \n",
        "        # Get sorted indices\n",
        "        sorted_idx = np.argsort(results['importances_mean'])[::-1]\n",
        "        \n",
        "        if rank <= len(sorted_idx):\n",
        "            idx = sorted_idx[rank - 1]\n",
        "            feature = results['feature_names'][idx]\n",
        "            importance = results['importances_mean'][idx]\n",
        "            std = results['importances_std'][idx]\n",
        "            \n",
        "            # Clean feature name\n",
        "            if feature.startswith('cat_low_'):\n",
        "                feature = feature.replace('cat_low_', '')\n",
        "            \n",
        "            row[f'{model_name.replace(\"_\", \" \").title()}\\nΔ AUC'] = f\"{importance:.3f} ± {std:.3f}\"\n",
        "            row['Feature'] = feature\n",
        "        else:\n",
        "            row[f'{model_name.replace(\"_\", \" \").title()}\\nΔ AUC'] = \"N/A\"\n",
        "    \n",
        "    table_data.append(row)\n",
        "\n",
        "# Create table with proper column ordering\n",
        "table_4_9 = pd.DataFrame(table_data)\n",
        "column_order = ['Rank', 'Feature', 'Logistic Regression\\nΔ AUC', 'Random Forest\\nΔ AUC', 'Xgboost\\nΔ AUC']\n",
        "table_4_9 = table_4_9[column_order]\n",
        "\n",
        "print(\"\\nTable 4.9: Top 10 Features by Permutation Importance (AUC Decrease)\")\n",
        "print(\"=\"*90)\n",
        "print(table_4_9.to_string(index=False))\n",
        "\n",
        "# Save table\n",
        "table_4_9.to_csv('../data/processed/table_4_9.csv', index=False)\n",
        "print(\"\\nTable 4.9 saved to ../data/processed/table_4_9.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shap-prep-header",
      "metadata": {},
      "source": [
        "## SHAP Analysis Preparation\n",
        "\n",
        "Prepare data for SHAP analysis by transforming features and creating explainers for tree-based models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shap-preparation",
      "metadata": {},
      "outputs": [],
      "source": [
        "# For SHAP, we need to work with transformed data\n",
        "# Transform a sample of data for SHAP analysis (to save memory)\n",
        "sample_size = min(1000, len(X_test))\n",
        "X_test_sample = X_test.sample(n=sample_size, random_state=RANDOM_SEED)\n",
        "y_test_sample = y_test.loc[X_test_sample.index]\n",
        "\n",
        "# Transform features for each model\n",
        "transformed_data = {}\n",
        "for model_name, pipeline in best_models.items():\n",
        "    # Get preprocessor\n",
        "    preprocessor = pipeline.named_steps['preprocessor']\n",
        "\n",
        "    # Transform the sample\n",
        "    X_transformed = preprocessor.transform(X_test_sample)\n",
        "\n",
        "    # Get the classifier\n",
        "    if 'smote' in pipeline.named_steps:\n",
        "        classifier = pipeline.named_steps['classifier']\n",
        "    else:\n",
        "        classifier = pipeline.named_steps.get('classifier', pipeline.named_steps.get('model'))\n",
        "\n",
        "    transformed_data[model_name] = {\n",
        "        'X_transformed': X_transformed,\n",
        "        'classifier': classifier,\n",
        "        'feature_names': get_feature_names(pipeline, X_test_sample.columns.tolist())\n",
        "    }\n",
        "\n",
        "print(f\"Transformed sample size: {sample_size}\")\n",
        "print(\"Data prepared for SHAP analysis!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shap-xgboost-header",
      "metadata": {},
      "source": [
        "## SHAP Analysis for XGBoost Model\n",
        "\n",
        "Detailed SHAP analysis for the XGBoost model, which typically provides the most accurate and interpretable SHAP values for tree-based models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shap-xgboost",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Focus on XGBoost as it typically provides the best SHAP visualizations\n",
        "model_name = 'xgboost'\n",
        "X_transformed = transformed_data[model_name]['X_transformed']\n",
        "classifier = transformed_data[model_name]['classifier']\n",
        "feature_names = transformed_data[model_name]['feature_names']\n",
        "\n",
        "print(\"Computing SHAP values for XGBoost model...\")\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(classifier)\n",
        "\n",
        "# Calculate SHAP values\n",
        "shap_values = explainer.shap_values(X_transformed)\n",
        "\n",
        "print(\"SHAP values computed successfully!\")\n",
        "print(f\"SHAP values shape: {shap_values.shape}\")\n",
        "print(f\"Feature names count: {len(feature_names)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "figure49-header",
      "metadata": {},
      "source": [
        "## Figure 4.9: SHAP Feature Importance for XGBoost Model\n",
        "\n",
        "Bar plot showing the most important features based on mean absolute SHAP values, providing insights into which features have the greatest impact on model predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "figure49-xgboost",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load evaluation results to get test metrics for annotation\n",
        "evaluation_results = joblib.load('../models/evaluation_results.pkl')\n",
        "test_metrics = evaluation_results['test_metrics']\n",
        "optimal_thresholds = evaluation_results['optimal_thresholds']\n",
        "\n",
        "# Create SHAP feature importance plot with better styling\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Calculate mean absolute SHAP values\n",
        "shap_importance = np.abs(shap_values).mean(axis=0)\n",
        "sorted_idx = np.argsort(shap_importance)[::-1][:20]  # Top 20 features\n",
        "\n",
        "# Prepare data for plotting\n",
        "top_features = [feature_names[i] for i in sorted_idx]\n",
        "top_importance = shap_importance[sorted_idx]\n",
        "\n",
        "# Clean feature names for display\n",
        "display_names = []\n",
        "for feat in top_features:\n",
        "    if feat.startswith('cat_low_'):\n",
        "        clean_name = feat.replace('cat_low_', '').replace('_', ' ').title()\n",
        "    elif feat.startswith('cat_high_'):\n",
        "        clean_name = feat.replace('cat_high_', '').replace('_', ' ').title()\n",
        "    else:\n",
        "        # Special handling for common features\n",
        "        if feat == 'amount_vs_mean_ratio':\n",
        "            clean_name = 'Amount vs Mean Ratio'\n",
        "        elif feat == 'velocity_score':\n",
        "            clean_name = 'Velocity Score'\n",
        "        elif feat == 'amount_sum_24h':\n",
        "            clean_name = 'Amount Sum (24H)'\n",
        "        elif feat == 'tx_count_24h':\n",
        "            clean_name = 'Transaction Count (24H)'\n",
        "        elif feat == 'amount_mean_7d':\n",
        "            clean_name = 'Amount Mean (7D)'\n",
        "        elif feat == 'amount_std_7d':\n",
        "            clean_name = 'Amount Std (7D)'\n",
        "        elif feat == 'composite_risk':\n",
        "            clean_name = 'Composite Risk Score'\n",
        "        elif feat == 'merchant_risk_score':\n",
        "            clean_name = 'Merchant Risk Score'\n",
        "        elif feat == 'online_channel_ratio':\n",
        "            clean_name = 'Online Channel Ratio'\n",
        "        else:\n",
        "            clean_name = feat.replace('_', ' ').title()\n",
        "    display_names.append(clean_name)\n",
        "\n",
        "# Create color gradient based on importance\n",
        "colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(top_importance)))\n",
        "\n",
        "# Create horizontal bar plot\n",
        "y_pos = np.arange(len(display_names))\n",
        "bars = plt.barh(y_pos, top_importance, color=colors, edgecolor='navy', linewidth=0.5)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, value) in enumerate(zip(bars, top_importance)):\n",
        "    plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,\n",
        "             f'{value:.4f}', va='center', fontsize=9, color='black')\n",
        "\n",
        "# Formatting\n",
        "plt.xlabel('Mean |SHAP value| (Average impact on model output)', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
        "plt.title('Figure 4.9: SHAP Feature Importance for XGBoost Model\\n(Nigerian Banking Fraud Detection)',\n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# Set y-axis\n",
        "plt.yticks(y_pos, display_names, fontsize=11)\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Add grid\n",
        "plt.grid(True, axis='x', alpha=0.3, linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Set x-axis limits\n",
        "plt.xlim(0, max(top_importance) * 1.15)\n",
        "\n",
        "# Add a text box with model info\n",
        "textstr = f'Model: XGBoost\\nAUC-ROC: {test_metrics[\"xgboost\"][\"AUC\"][\"mean\"]:.4f}\\nOptimal Threshold: {optimal_thresholds[\"xgboost\"]:.3f}'\n",
        "props = dict(boxstyle='round', facecolor='lightblue', alpha=0.5)\n",
        "plt.text(0.98, 0.97, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
        "         verticalalignment='top', horizontalalignment='right', bbox=props)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../docs/images/figure_4_9_shap_xgboost.png',\n",
        "            dpi=300, bbox_inches='tight', facecolor='white')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shap-rf-header",
      "metadata": {},
      "source": [
        "## SHAP Analysis for Random Forest Model\n",
        "\n",
        "Calculate SHAP values for Random Forest to compare feature importance patterns across different tree-based algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shap-random-forest",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate SHAP values for Random Forest\n",
        "print(\"Computing SHAP values for Random Forest model...\")\n",
        "\n",
        "# Get Random Forest components\n",
        "rf_transformed = transformed_data['random_forest']['X_transformed']\n",
        "rf_classifier = transformed_data['random_forest']['classifier']\n",
        "rf_feature_names = transformed_data['random_forest']['feature_names']\n",
        "\n",
        "# Create SHAP explainer for Random Forest\n",
        "rf_explainer = shap.TreeExplainer(rf_classifier)\n",
        "\n",
        "# Calculate SHAP values (this may take a while for Random Forest)\n",
        "rf_shap_values = rf_explainer.shap_values(rf_transformed)\n",
        "\n",
        "# For binary classification, take the positive class SHAP values\n",
        "if isinstance(rf_shap_values, list):\n",
        "    rf_shap_values = rf_shap_values[1]\n",
        "\n",
        "print(\"SHAP values computed successfully for Random Forest!\")\n",
        "print(f\"RF SHAP values shape: {rf_shap_values.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "figure49a-header",
      "metadata": {},
      "source": [
        "## Figure 4.9a: SHAP Feature Importance for Random Forest Model\n",
        "\n",
        "Comparison plot showing Random Forest SHAP feature importance with green color theme."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "figure49a-random-forest",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Calculate mean absolute SHAP values for Random Forest\n",
        "rf_shap_importance = np.abs(rf_shap_values).mean(axis=0)\n",
        "\n",
        "# Debug: Check shapes and ensure compatibility\n",
        "print(f\"rf_shap_importance shape: {rf_shap_importance.shape}\")\n",
        "print(f\"rf_feature_names length: {len(rf_feature_names)}\")\n",
        "\n",
        "# Ensure rf_shap_importance is 1D\n",
        "if rf_shap_importance.ndim > 1:\n",
        "    rf_shap_importance = rf_shap_importance.flatten()\n",
        "\n",
        "# Ensure feature names and importance values have matching lengths\n",
        "min_length = min(len(rf_feature_names), len(rf_shap_importance))\n",
        "rf_feature_names = rf_feature_names[:min_length]\n",
        "rf_shap_importance = rf_shap_importance[:min_length]\n",
        "\n",
        "# Sort indices\n",
        "rf_sorted_idx = np.argsort(rf_shap_importance)[::-1]\n",
        "\n",
        "# Prepare data for plotting\n",
        "top_n = min(20, len(rf_feature_names))\n",
        "rf_features_and_importance = []\n",
        "for idx in rf_sorted_idx:\n",
        "    if idx < len(rf_feature_names) and idx < len(rf_shap_importance):\n",
        "        rf_features_and_importance.append((rf_feature_names[idx], rf_shap_importance[idx]))\n",
        "\n",
        "rf_top_features_and_importance = rf_features_and_importance[:top_n]\n",
        "rf_top_features = [feat for feat, importance in rf_top_features_and_importance]\n",
        "rf_top_importance = [importance for feat, importance in rf_top_features_and_importance]\n",
        "\n",
        "# Clean feature names for display (same logic as XGBoost)\n",
        "rf_display_names = []\n",
        "for feat in rf_top_features:\n",
        "    if feat.startswith('cat_low_'):\n",
        "        clean_name = feat.replace('cat_low_', '').replace('_', ' ').title()\n",
        "    elif feat.startswith('cat_high_'):\n",
        "        clean_name = feat.replace('cat_high_', '').replace('_', ' ').title()\n",
        "    else:\n",
        "        # Special handling for common features\n",
        "        if feat == 'amount_vs_mean_ratio':\n",
        "            clean_name = 'Amount vs Mean Ratio'\n",
        "        elif feat == 'velocity_score':\n",
        "            clean_name = 'Velocity Score'\n",
        "        elif feat == 'amount_sum_24h':\n",
        "            clean_name = 'Amount Sum (24H)'\n",
        "        elif feat == 'tx_count_24h':\n",
        "            clean_name = 'Transaction Count (24H)'\n",
        "        elif feat == 'amount_mean_7d':\n",
        "            clean_name = 'Amount Mean (7D)'\n",
        "        elif feat == 'amount_std_7d':\n",
        "            clean_name = 'Amount Std (7D)'\n",
        "        elif feat == 'composite_risk':\n",
        "            clean_name = 'Composite Risk Score'\n",
        "        elif feat == 'merchant_risk_score':\n",
        "            clean_name = 'Merchant Risk Score'\n",
        "        elif feat == 'online_channel_ratio':\n",
        "            clean_name = 'Online Channel Ratio'\n",
        "        else:\n",
        "            clean_name = feat.replace('_', ' ').title()\n",
        "    rf_display_names.append(clean_name)\n",
        "\n",
        "# Create color gradient - use green theme for Random Forest\n",
        "colors = plt.cm.Greens(np.linspace(0.4, 0.9, len(rf_top_importance)))\n",
        "\n",
        "# Create horizontal bar plot\n",
        "y_pos = np.arange(len(rf_display_names))\n",
        "bars = plt.barh(y_pos, rf_top_importance, color=colors, edgecolor='darkgreen', linewidth=0.5)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, value) in enumerate(zip(bars, rf_top_importance)):\n",
        "    plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,\n",
        "             f'{value:.4f}', va='center', fontsize=9, color='black')\n",
        "\n",
        "# Formatting\n",
        "plt.xlabel('Mean |SHAP value| (Average impact on model output)', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
        "plt.title('Figure 4.9a: SHAP Feature Importance for Random Forest Model\\n(Nigerian Banking Fraud Detection)',\n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# Set y-axis\n",
        "plt.yticks(y_pos, rf_display_names, fontsize=11)\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Add grid\n",
        "plt.grid(True, axis='x', alpha=0.3, linestyle='--', linewidth=0.5)\n",
        "\n",
        "# Set x-axis limits\n",
        "plt.xlim(0, max(rf_top_importance) * 1.15)\n",
        "\n",
        "# Add a text box with model info\n",
        "textstr = f'Model: Random Forest\\nAUC-ROC: {test_metrics[\"random_forest\"][\"AUC\"][\"mean\"]:.4f}'\n",
        "props = dict(boxstyle='round', facecolor='lightgreen', alpha=0.5)\n",
        "plt.text(0.98, 0.97, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
        "         verticalalignment='top', horizontalalignment='right', bbox=props)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../docs/images/figure_4_9a_shap_random_forest.png',\n",
        "            dpi=300, bbox_inches='tight', facecolor='white')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shap-comparison-header",
      "metadata": {},
      "source": [
        "## Comparative SHAP Analysis: XGBoost vs Random Forest\n",
        "\n",
        "Side-by-side comparison of feature importance rankings between XGBoost and Random Forest models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shap-comparison",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create side-by-side comparison of top features\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "# XGBoost plot\n",
        "y_pos_xgb = np.arange(15)  # Top 15 for comparison\n",
        "ax1.barh(y_pos_xgb, top_importance[:15], color='#45B7D1', alpha=0.8, edgecolor='navy', linewidth=0.5)\n",
        "ax1.set_yticks(y_pos_xgb)\n",
        "ax1.set_yticklabels(display_names[:15], fontsize=10)\n",
        "ax1.invert_yaxis()\n",
        "ax1.set_xlabel('Mean |SHAP value|', fontsize=11, fontweight='bold')\n",
        "ax1.set_title('XGBoost Model', fontsize=13, fontweight='bold')\n",
        "ax1.grid(True, axis='x', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Random Forest plot\n",
        "y_pos_rf = np.arange(15)  # Top 15 for comparison\n",
        "ax2.barh(y_pos_rf, rf_top_importance[:15], color='#4ECDC4', alpha=0.8, edgecolor='darkgreen', linewidth=0.5)\n",
        "ax2.set_yticks(y_pos_rf)\n",
        "ax2.set_yticklabels(rf_display_names[:15], fontsize=10)\n",
        "ax2.invert_yaxis()\n",
        "ax2.set_xlabel('Mean |SHAP value|', fontsize=11, fontweight='bold')\n",
        "ax2.set_title('Random Forest Model', fontsize=13, fontweight='bold')\n",
        "ax2.grid(True, axis='x', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Overall title\n",
        "fig.suptitle('SHAP Feature Importance Comparison: XGBoost vs Random Forest\\n(Top 15 Features)',\n",
        "             fontsize=15, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../docs/images/figure_shap_comparison.png',\n",
        "            dpi=300, bbox_inches='tight', facecolor='white')\n",
        "plt.show()\n",
        "\n",
        "# Print feature importance comparison\n",
        "print(\"\\nTop 5 Features Comparison:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Rank':<6} {'XGBoost':<30} {'Random Forest':<30}\")\n",
        "print(\"-\"*60)\n",
        "for i in range(5):\n",
        "    xgb_feat = display_names[i] if i < len(display_names) else \"N/A\"\n",
        "    rf_feat = rf_display_names[i] if i < len(rf_display_names) else \"N/A\"\n",
        "    print(f\"{i+1:<6} {xgb_feat:<30} {rf_feat:<30}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shap-summary-header",
      "metadata": {},
      "source": [
        "## SHAP Summary Plot\n",
        "\n",
        "Detailed SHAP summary plot showing the relationship between feature values and their impact on model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "shap-summary-plot",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create detailed SHAP summary plot\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Create summary plot showing feature values\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_transformed,\n",
        "    feature_names=feature_names,\n",
        "    max_display=20,\n",
        "    show=False\n",
        ")\n",
        "\n",
        "plt.title('SHAP Summary Plot: Feature Impact on Fraud Detection', fontsize=14)\n",
        "plt.xlabel('SHAP value (impact on model output)', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../docs/images/shap_summary_detailed.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "channel-specific-header",
      "metadata": {},
      "source": [
        "## Channel-Specific SHAP Analysis\n",
        "\n",
        "Analysis of how feature importance varies across different banking channels (ATM, Mobile, POS, Web)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "channel-specific-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze SHAP values by channel\n",
        "channels = X_test_sample['channel'].unique()\n",
        "channel_shap_analysis = {}\n",
        "\n",
        "for channel in channels:\n",
        "    # Get indices for this channel\n",
        "    channel_mask = X_test_sample['channel'] == channel\n",
        "    channel_indices = np.where(channel_mask)[0]\n",
        "\n",
        "    if len(channel_indices) > 0:\n",
        "        # Calculate mean absolute SHAP values for this channel\n",
        "        channel_shap = np.abs(shap_values[channel_indices]).mean(axis=0)\n",
        "        channel_shap_analysis[channel] = channel_shap\n",
        "\n",
        "# Create comparison plot\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Select top features for comparison\n",
        "top_n_features = 10\n",
        "overall_importance = np.abs(shap_values).mean(axis=0)\n",
        "top_indices = np.argsort(overall_importance)[::-1][:top_n_features]\n",
        "\n",
        "# Prepare data for plotting\n",
        "x = np.arange(top_n_features)\n",
        "width = 0.25\n",
        "\n",
        "# Plot bars for each channel\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
        "for i, (channel, color) in enumerate(zip(sorted(channels), colors)):\n",
        "    if channel in channel_shap_analysis:\n",
        "        values = [channel_shap_analysis[channel][idx] for idx in top_indices]\n",
        "        ax.bar(x + i*width, values, width, label=channel, color=color, alpha=0.8)\n",
        "\n",
        "# Customize plot\n",
        "feature_labels = [feature_names[idx].replace('_', ' ').title() for idx in top_indices]\n",
        "ax.set_xlabel('Features', fontsize=12)\n",
        "ax.set_ylabel('Mean |SHAP value|', fontsize=12)\n",
        "ax.set_title('Channel-Specific Feature Importance', fontsize=14)\n",
        "ax.set_xticks(x + width * 1.5)\n",
        "ax.set_xticklabels(feature_labels, rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../docs/images/channel_specific_shap.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Channel-specific SHAP analysis completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feature-relationships-header",
      "metadata": {},
      "source": [
        "## Feature Value vs SHAP Value Relationships\n",
        "\n",
        "Scatter plots showing how feature values relate to their SHAP values for the top 6 most important features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feature-relationships",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze how feature values correlate with their SHAP values\n",
        "# Focus on top features\n",
        "top_features_idx = np.argsort(np.abs(shap_values).mean(axis=0))[::-1][:6]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature_idx in enumerate(top_features_idx):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Get feature values and SHAP values\n",
        "    feature_values = X_transformed[:, feature_idx]\n",
        "    feature_shap = shap_values[:, feature_idx]\n",
        "\n",
        "    # Create scatter plot\n",
        "    scatter = ax.scatter(feature_values, feature_shap,\n",
        "                        c=feature_shap, cmap='coolwarm',\n",
        "                        alpha=0.6, s=30)\n",
        "\n",
        "    ax.set_xlabel(f'{feature_names[feature_idx]}', fontsize=10)\n",
        "    ax.set_ylabel('SHAP value', fontsize=10)\n",
        "    ax.set_title(f'SHAP vs {feature_names[feature_idx]}', fontsize=11)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(scatter, ax=ax)\n",
        "    cbar.set_label('SHAP value', fontsize=8)\n",
        "\n",
        "plt.suptitle('Feature Value vs SHAP Value Relationships', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../docs/images/shap_feature_relationships.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "temporal-analysis-header",
      "metadata": {},
      "source": [
        "## Temporal Feature Importance Analysis\n",
        "\n",
        "Analysis of how temporal features (time-based features) contribute to fraud detection across different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "temporal-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze temporal features' importance\n",
        "temporal_features = ['hour', 'day_of_week', 'month', 'hour_sin', 'hour_cos',\n",
        "                    'day_sin', 'day_cos', 'month_sin', 'month_cos', 'is_weekend', 'is_peak_hour']\n",
        "\n",
        "# Get indices of temporal features\n",
        "temporal_indices = []\n",
        "for i, feat in enumerate(feature_names):\n",
        "    if any(temp in feat for temp in temporal_features):\n",
        "        temporal_indices.append(i)\n",
        "\n",
        "# Calculate temporal feature importance\n",
        "temporal_importance = {}\n",
        "for model_name in best_models.keys():\n",
        "    results = perm_importance_results[model_name]\n",
        "    temp_imp = []\n",
        "\n",
        "    for idx in temporal_indices:\n",
        "        if idx < len(results['importances_mean']):\n",
        "            temp_imp.append(results['importances_mean'][idx])\n",
        "\n",
        "    temporal_importance[model_name] = np.mean(temp_imp) if temp_imp else 0\n",
        "\n",
        "# Create comparison plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "models = list(temporal_importance.keys())\n",
        "values = list(temporal_importance.values())\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "\n",
        "bars = plt.bar(range(len(models)), values, color=colors, alpha=0.8)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, value in zip(bars, values):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.0001,\n",
        "             f'{value:.4f}', ha='center', va='bottom')\n",
        "\n",
        "plt.xlabel('Model', fontsize=12)\n",
        "plt.ylabel('Average Importance of Temporal Features', fontsize=12)\n",
        "plt.title('Temporal Feature Importance Across Models', fontsize=14)\n",
        "plt.xticks(range(len(models)), [m.replace('_', ' ').title() for m in models])\n",
        "plt.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../docs/images/temporal_feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTemporal Feature Importance Summary:\")\n",
        "print(\"=\"*50)\n",
        "for model_name, importance in temporal_importance.items():\n",
        "    print(f\"{model_name.replace('_', ' ').title()}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "save-results-header",
      "metadata": {},
      "source": [
        "## Save Feature Importance Results\n",
        "\n",
        "Compile and save all feature importance analysis results for subsequent use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "save-results",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile all feature importance results\n",
        "feature_importance_results = {\n",
        "    'permutation_importance': perm_importance_results,\n",
        "    'shap_values': {\n",
        "        'xgboost': {\n",
        "            'values': shap_values,\n",
        "            'expected_value': explainer.expected_value,\n",
        "            'feature_names': feature_names\n",
        "        },\n",
        "        'random_forest': {\n",
        "            'values': rf_shap_values,\n",
        "            'expected_value': rf_explainer.expected_value,\n",
        "            'feature_names': rf_feature_names\n",
        "        }\n",
        "    },\n",
        "    'channel_analysis': channel_shap_analysis,\n",
        "    'temporal_importance': temporal_importance,\n",
        "    'tables': {\n",
        "        'table_4_9': table_4_9\n",
        "    },\n",
        "    'top_features_analysis': {\n",
        "        'xgboost_top_features': top_features,\n",
        "        'xgboost_importance': top_importance,\n",
        "        'rf_top_features': rf_top_features,\n",
        "        'rf_importance': rf_top_importance\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save results\n",
        "joblib.dump(feature_importance_results, '../models/feature_importance_results.pkl')\n",
        "\n",
        "print(\"Feature importance analysis completed and saved!\")\n",
        "print(\"\\nKey findings:\")\n",
        "print(f\"1. Top feature across all models: {table_4_9.iloc[0]['Feature']}\")\n",
        "print(f\"2. Average temporal feature importance: {np.mean(list(temporal_importance.values())):.4f}\")\n",
        "print(f\"3. Number of features with positive importance: {np.sum(shap_importance > 0)}\")\n",
        "print(f\"4. XGBoost vs Random Forest top feature agreement: {len(set(display_names[:5]).intersection(set(rf_display_names[:5])))} out of 5\")\n",
        "\n",
        "print(\"\\nFiles created:\")\n",
        "print(\"- ../models/feature_importance_results.pkl\")\n",
        "print(\"- ../data/processed/table_4_9.csv\")\n",
        "print(\"- ../docs/images/figure_4_9_shap_xgboost.png\")\n",
        "print(\"- ../docs/images/figure_4_9a_shap_random_forest.png\")\n",
        "print(\"- ../docs/images/figure_shap_comparison.png\")\n",
        "print(\"- ../docs/images/shap_summary_detailed.png\")\n",
        "print(\"- ../docs/images/channel_specific_shap.png\")\n",
        "print(\"- ../docs/images/shap_feature_relationships.png\")\n",
        "print(\"- ../docs/images/temporal_feature_importance.png\")\n",
        "\n",
        "print(\"\\nReady for cost-sensitive analysis in next notebook!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}